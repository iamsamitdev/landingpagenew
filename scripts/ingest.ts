import { PDFLoader } from "@langchain/community/document_loaders/fs/pdf"
import { RecursiveCharacterTextSplitter } from "@langchain/textsplitters"
import { OpenAIEmbeddings } from "@langchain/openai"
import { createClient } from "@supabase/supabase-js"
import { Document } from "@langchain/core/documents"
import fs from "fs"
import path from "path"
import dotenv from "dotenv"

// ‡πÇ‡∏´‡∏•‡∏î environment variables
dotenv.config({ path: ".env.local" })
dotenv.config({ path: ".env" })

// ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö environment variables
const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY
const openaiApiKey = process.env.OPENAI_API_KEY

if (!supabaseUrl || !supabaseServiceKey) {
  console.error("‚ùå Missing Supabase credentials in environment variables")
  console.log("Required: NEXT_PUBLIC_SUPABASE_URL, SUPABASE_SERVICE_ROLE_KEY")
  process.exit(1)
}

if (!openaiApiKey) {
  console.error("‚ùå Missing OPENAI_API_KEY in environment variables")
  process.exit(1)
}

// ‡∏™‡∏£‡πâ‡∏≤‡∏á Supabase Admin Client
const supabaseAdmin = createClient(supabaseUrl, supabaseServiceKey)

// ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
const DOCUMENTS_PATH = "./documents"

async function ingestDocuments() {
  console.log("üöÄ Starting document ingestion...")
  console.log(`üìÇ Looking for documents in: ${path.resolve(DOCUMENTS_PATH)}`)

  // ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå documents ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
  if (!fs.existsSync(DOCUMENTS_PATH)) {
    fs.mkdirSync(DOCUMENTS_PATH, { recursive: true })
    console.log("üìÅ Created documents folder. Please add PDF or TXT files and run again.")
    return
  }

  // ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå
  const files = fs.readdirSync(DOCUMENTS_PATH)
  const pdfFiles = files.filter(f => f.endsWith(".pdf"))
  const txtFiles = files.filter(f => f.endsWith(".txt"))

  if (pdfFiles.length === 0 && txtFiles.length === 0) {
    console.log("‚ö†Ô∏è No PDF or TXT files found in documents folder.")
    console.log("üìù Please add documents to the 'documents' folder and run again.")
    return
  }

  console.log(`üìö Found ${pdfFiles.length} PDF files and ${txtFiles.length} TXT files`)

  const allDocs = []

  // ‡πÇ‡∏´‡∏•‡∏î PDF files
  for (const file of pdfFiles) {
    const filePath = path.join(DOCUMENTS_PATH, file)
    console.log(`üìÑ Loading PDF: ${file}`)
    
    try {
      const loader = new PDFLoader(filePath)
      const docs = await loader.load()
      
      // ‡πÄ‡∏û‡∏¥‡πà‡∏° metadata
      docs.forEach(doc => {
        doc.metadata = {
          ...doc.metadata,
          source: file,
          type: "pdf",
        }
      })
      
      allDocs.push(...docs)
      console.log(`   ‚úÖ Loaded ${docs.length} pages from ${file}`)
    } catch (error) {
      console.error(`   ‚ùå Error loading ${file}:`, error)
    }
  }

  // ‡πÇ‡∏´‡∏•‡∏î TXT files (‡πÉ‡∏ä‡πâ fs ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á)
  for (const file of txtFiles) {
    const filePath = path.join(DOCUMENTS_PATH, file)
    console.log(`üìÑ Loading TXT: ${file}`)
    
    try {
      const content = fs.readFileSync(filePath, "utf-8")
      const doc = new Document({
        pageContent: content,
        metadata: {
          source: file,
          type: "txt",
        },
      })
      
      allDocs.push(doc)
      console.log(`   ‚úÖ Loaded ${file}`)
    } catch (error) {
      console.error(`   ‚ùå Error loading ${file}:`, error)
    }
  }

  if (allDocs.length === 0) {
    console.log("‚ùå No documents could be loaded. Please check your files.")
    return
  }

  console.log(`\nüìö Total documents loaded: ${allDocs.length}`)

  // ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô Chunks
  console.log("\n‚úÇÔ∏è Splitting documents into chunks...")
  const textSplitter = new RecursiveCharacterTextSplitter({
    chunkSize: 1000,
    chunkOverlap: 200,
  })

  const splitDocs = await textSplitter.splitDocuments(allDocs)
  console.log(`‚úÖ Created ${splitDocs.length} chunks`)

  // ‡∏™‡∏£‡πâ‡∏≤‡∏á Embeddings
  console.log("\nüîÑ Creating embeddings...")
  const embeddings = new OpenAIEmbeddings({
    modelName: "text-embedding-3-small",
    openAIApiKey: openaiApiKey,
  })

  // ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏≠‡∏≠‡∏Å‡∏Å‡πà‡∏≠‡∏ô (optional)
  console.log("üóëÔ∏è Clearing existing documents...")
  const { error: deleteError } = await supabaseAdmin
    .from("documents")
    .delete()
    .neq("id", 0) // ‡∏•‡∏ö‡∏ó‡∏∏‡∏Å row

  if (deleteError) {
    console.warn("‚ö†Ô∏è Could not clear existing documents:", deleteError.message)
  }

  // ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á Supabase
  console.log("\nüíæ Saving to Supabase...")
  let successCount = 0
  let errorCount = 0

  for (let i = 0; i < splitDocs.length; i++) {
    const doc = splitDocs[i]
    
    try {
      // ‡∏™‡∏£‡πâ‡∏≤‡∏á embedding ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö chunk ‡∏ô‡∏µ‡πâ
      const embedding = await embeddings.embedQuery(doc.pageContent)

      // ‡πÅ‡∏õ‡∏•‡∏á embedding array ‡πÄ‡∏õ‡πá‡∏ô pgvector format string: [0.1,0.2,0.3,...]
      const embeddingString = `[${embedding.join(",")}]`

      // ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á database
      const { error } = await supabaseAdmin.from("documents").insert({
        content: doc.pageContent,
        metadata: doc.metadata,
        embedding: embeddingString,
      })

      if (error) {
        console.error(`‚ùå Error saving chunk ${i + 1}:`, error.message)
        errorCount++
      } else {
        successCount++
        // ‡πÅ‡∏™‡∏î‡∏á progress ‡∏ó‡∏∏‡∏Å 10 chunks
        if ((i + 1) % 10 === 0 || i === splitDocs.length - 1) {
          const progress = Math.round(((i + 1) / splitDocs.length) * 100)
          console.log(`   üìä Progress: ${i + 1}/${splitDocs.length} (${progress}%)`)
        }
      }
    } catch (error) {
      console.error(`‚ùå Error processing chunk ${i + 1}:`, error)
      errorCount++
    }
  }

  console.log("\n" + "=".repeat(50))
  console.log("üéâ Document ingestion completed!")
  console.log(`‚úÖ Successfully saved: ${successCount} chunks`)
  if (errorCount > 0) {
    console.log(`‚ùå Failed: ${errorCount} chunks`)
  }
  console.log("=".repeat(50))
}

// ‡∏£‡∏±‡∏ô script
ingestDocuments().catch(error => {
  console.error("‚ùå Fatal error:", error)
  process.exit(1)
})
